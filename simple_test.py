#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹ Ù…Ø¯Ù„
"""

import torch
from model import ConvE
from spodernet.preprocessing.pipeline import Pipeline
from spodernet.preprocessing.batching import StreamBatcher
from spodernet.utils.global_config import Config
from evaluation import ranking_and_hits

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
Config.backend = 'pytorch'
Config.cuda = True
Config.embedding_dim = 200

print("=" * 70)
print("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Dataset Ùˆ Vocabulary")
print("=" * 70)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ vocabulary
input_keys = ['e1', 'rel', 'rel_eval', 'e2', 'e2_multi1', 'e2_multi2']
p = Pipeline('FB15k-237', keys=input_keys)

# Ø³Ø¹ÛŒ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ vocabulary
try:
    p.load_vocabs()
except:
    print("\nâš ï¸  Vocabulary outdated ÛŒØ§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯!")
    print("Ø¯Ø± Ø­Ø§Ù„ rebuild Ú©Ø±Ø¯Ù† vocabulary Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON...")
    import sys
    sys.exit(1)

vocab = p.state['vocab']

num_entities = vocab['e1'].num_token
num_relations = vocab['rel'].num_token

# Ø¨Ø±Ø±Ø³ÛŒ ØµØ­Øª vocabulary
if num_entities < 100 or num_relations < 10:
    print(f"\nâŒ Ø®Ø·Ø§: Vocabulary Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª!")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Entities: {num_entities} (Ø¨Ø§ÛŒØ¯ 14543 Ø¨Ø§Ø´Ø¯)")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Relations: {num_relations} (Ø¨Ø§ÛŒØ¯ 476 Ø¨Ø§Ø´Ø¯)")
    print("\nğŸ’¡ Ù„Ø·ÙØ§Ù‹ Ù…Ø±Ø§Ø­Ù„ Ø²ÛŒØ± Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯:")
    print("   1. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ vocabulary Ù‚Ø¯ÛŒÙ…ÛŒ Ø±Ø§ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯:")
    print("      rm -rf ~/.data/FB15k-237/vocab*")
    print("   2. Ø¯ÙˆØ¨Ø§Ø±Ù‡ preprocessing Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯ (ÙÙ‚Ø· ØªØ§ vocab Ø³Ø§Ø®ØªÙ‡ Ø´ÙˆØ¯):")
    print("      python main.py --data FB15k-237 --preprocess")
    print("      (Ø¨Ø¹Ø¯ Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ vocab Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ØŒ Ø¨Ø§ Ctrl+C Ù…ØªÙˆÙ‚ÙØ´ Ú©Ù†ÛŒØ¯)")
    import sys
    sys.exit(1)

print(f"âœ“ ØªØ¹Ø¯Ø§Ø¯ Entities: {num_entities}")
print(f"âœ“ ØªØ¹Ø¯Ø§Ø¯ Relations: {num_relations}")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ batch loaders
test_rank_batcher = StreamBatcher(
    'FB15k-237', 
    'test_ranking', 
    128, 
    randomize=False, 
    loader_threads=4, 
    keys=input_keys
)

print("\n" + "=" * 70)
print("Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„")
print("=" * 70)

# Ø§ÛŒØ¬Ø§Ø¯ args object
class Args:
    embedding_dim = 200
    embedding_shape1 = 20
    hidden_drop = 0.3
    input_drop = 0.2
    feat_drop = 0.2
    hidden_size = 9728
    use_bias = False  # Ù…Ø¯Ù„ Ø¨Ø¯ÙˆÙ† bias Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª

args = Args()

# Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„
model = ConvE(args, num_entities, num_relations)
print(model)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§
model_path = 'saved_models/FB15k-237_conve_0.2_0.3.model'
print(f"\n Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø§Ø²: {model_path}")
model_params = torch.load(model_path, weights_only=False)
model.load_state_dict(model_params)

# Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ GPU
model.cuda()
model.eval()

print("\n" + "=" * 70)
print("Ø´Ø±ÙˆØ¹ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Test Set")
print("=" * 70)

# ØªØ³Øª
with torch.no_grad():
    ranking_and_hits(model, test_rank_batcher, vocab, 'Test Evaluation')

print("\n" + "=" * 70)
print("ØªØ³Øª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
print("=" * 70)
